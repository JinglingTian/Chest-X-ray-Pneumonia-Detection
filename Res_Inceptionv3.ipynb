{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms,datasets\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集：多种肺炎X光图像,四分类\n",
    "## 网络: Residua+Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"./data/COVID_Dataset\"\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "VAL = 'val'\n",
    "\n",
    "def apply_transform(mode=None):\n",
    "    size = (299,299)\n",
    "    crop = 299\n",
    "    if mode == 'train':\n",
    "        transform = transforms.Compose([transforms.Resize(size),\n",
    "                               transforms.RandomHorizontalFlip(),\n",
    "                               transforms.RandomRotation((-20,+20)),\n",
    "                               transforms.CenterCrop(crop),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                           [0.229, 0.224, 0.225])\n",
    "                              ])\n",
    "\n",
    "    elif mode == 'test' or mode == 'val':\n",
    "        transform = transforms.Compose([transforms.Resize(size),\n",
    "                               transforms.CenterCrop(crop),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                           [0.229, 0.224, 0.225])\n",
    "                              ])\n",
    "\n",
    "    return transform\n",
    "\n",
    "trainset = datasets.ImageFolder(os.path.join(data_dir, TRAIN),\n",
    "                                transform = apply_transform(TRAIN))\n",
    "\n",
    "trainset,valset = random_split(trainset,[len(trainset)-int(len(trainset)*0.1),int(len(trainset)*0.1)])\n",
    "\n",
    "testset = datasets.ImageFolder(os.path.join(data_dir, TEST),\n",
    "                               transform = apply_transform(TEST))\n",
    "\n",
    "train_loader = DataLoader(trainset,\n",
    "                          batch_size=50,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(valset,\n",
    "                        batch_size=10)\n",
    "\n",
    "test_loader = DataLoader(testset,\n",
    "                         batch_size=1)\n",
    "\n",
    "len(train_loader),len(test_loader),len(val_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SA模块\n",
    "class SA_Layer(nn.Module):\n",
    "    def __init__(self,channels,groups=64) -> None:\n",
    "        super().__init__()\n",
    "        self.groups = groups\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.cweight = Parameter(torch.zeros(1,channels//(2*groups),1,1))\n",
    "        self.cbias = Parameter(torch.ones(1,channels//(2*groups),1,1))\n",
    "        self.sweight = Parameter(torch.zeros(1,channels//(2*groups),1,1))\n",
    "        self.sbias = Parameter(torch.ones(1,channels//(2*groups),1,1))\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.gn = nn.GroupNorm(channels//(2*groups),channels//(2*groups))\n",
    "\n",
    "    @staticmethod\n",
    "    def channel_suffle(x,groups):\n",
    "        b,c,h,w = x.shape\n",
    "        # 输入特征图分组\n",
    "        x = x.reshape(b,groups,-1,h,w)\n",
    "        # 洗牌\n",
    "        x = x.permute(0,2,1,3,4)\n",
    "        x = x.reshape(b,-1,h,w)\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def forward(self,x):\n",
    "        b,c,h,w = x.shape\n",
    "        x = x.reshape(b*self.groups,-1,h,w)\n",
    "        x_0, x_1 = x.chunk(2,dim=1)\n",
    "\n",
    "        # 通道注意力\n",
    "        xn = self.avg_pool(x_0)\n",
    "        xn = self.cweight * xn + self.cbias\n",
    "        xn = x_0*self.sigmoid(xn)\n",
    "\n",
    "        # 空间注意力\n",
    "        xs = self.gn(x_1)\n",
    "        xs = self.sweight * xs + self.sbias\n",
    "        xs = x_1*self.sigmoid(xs)\n",
    "\n",
    "        # 在通道维度上拼接\n",
    "        out = torch.cat([xn,xs],dim=1)\n",
    "        out = out.reshape(b,-1,h,w)\n",
    "        out = self.channel_suffle(out,2)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Inception层\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self,in_channels,c1,c2,c3,c4) -> None:\n",
    "        super().__init__()\n",
    "        # 路线1    1*1conv\n",
    "        self.route1x1_1 = nn.Conv2d(in_channels,c1,kernel_size=(1,1))\n",
    "        # 路线2    1*1conv,3*3conv\n",
    "        self.route1x1_2 = nn.Conv2d(in_channels,c2[0],kernel_size=(1,1))\n",
    "        self.route3x3_2 = nn.Conv2d(c2[0],c2[1],kernel_size=(3,3),padding=1)       \n",
    "        # 路线3    1*1conv,5*5conv\n",
    "        self.route1x1_3 = nn.Conv2d(in_channels,c3[0],kernel_size=(1,1))\n",
    "        self.route5x5_3 = nn.Conv2d(c3[0],c3[1],kernel_size=(5,5),padding=2)\n",
    "        # 路线4    3*3pool,1*1conv\n",
    "        self.route3x3_4 = nn.MaxPool2d((3,3),stride=1,padding=1)\n",
    "        self.route1x1_4 = nn.Conv2d(in_channels,c4,kernel_size=(1,1))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        route1 = F.relu(self.route1x1_1(x))\n",
    "        route2 = F.relu(self.route3x3_2(F.relu(self.route1x1_2(x))))\n",
    "        route3 = F.relu(self.route5x5_3(F.relu(self.route1x1_3(x))))\n",
    "        route4 = F.relu(self.route1x1_4(self.route3x3_4(x)))\n",
    "        out = torch.concat([route1,route2,route3,route4],dim=1)\n",
    "        return out\n",
    "\n",
    "# Basic卷积层\n",
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel,stride=1,padding=0) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=kernel,stride=stride,padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# Inception 残差块\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,strid=1) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels,out_channels,kernel_size=(1,1),stride=1)\n",
    "        self.inception = nn.Sequential(Inception(256,64,(64,128),(16,32),32))\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        y = self.inception(x)\n",
    "        out = F.relu(x+y)\n",
    "        return out\n",
    "\n",
    "# 网络\n",
    "class Res_Inception(nn.Module):\n",
    "    def __init__(self,in_channel,num_classes) -> None:\n",
    "        super().__init__()\n",
    "        self.b1 = nn.Sequential(\n",
    "            BasicConv2d(in_channel,out_channels=64,kernel=(3,3),stride=2,padding=1),\n",
    "            nn.MaxPool2d((2,2),2)\n",
    "        )\n",
    "        self.b2 = nn.Sequential(\n",
    "            BasicConv2d(64,128,kernel=(3,3),padding=1),\n",
    "            nn.MaxPool2d((2,2),2)\n",
    "        )\n",
    "        self.b3 = nn.Sequential(\n",
    "            BasicConv2d(128,256,kernel=(3,3),padding=1),\n",
    "            nn.MaxPool2d((2,2),2),\n",
    "        )\n",
    "        self.b4 = nn.Sequential(\n",
    "            BasicConv2d(256,256,kernel=(3,3),padding=1),\n",
    "            nn.MaxPool2d((2,2),2)\n",
    "        )\n",
    "        self.b5 = nn.Sequential(\n",
    "            Residual(256,256),\n",
    "            nn.MaxPool2d((2,2),2),\n",
    "            Residual(256,256),\n",
    "            nn.MaxPool2d((2,2),2),\n",
    "            Residual(256,256)\n",
    "        )\n",
    "        self.AvgPool2D = nn.AvgPool2d((2,2),2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.b6 = nn.Linear(256,num_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.b1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.b4(x)\n",
    "        x = self.b5(x)\n",
    "        x = self.AvgPool2D(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.b6(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "    preds = torch.exp(preds)\n",
    "    top_p,top_class = preds.topk(1, dim=1)\n",
    "    equals = top_class == labels.view(*top_class.shape)\n",
    "    return torch.mean(equals.type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Res_Inception(3,4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "schedular = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=3)\n",
    "\n",
    "epochs = 50\n",
    "val_loss_min = np.Inf\n",
    "max_e = 10\n",
    "\n",
    "# 模型存放路径\n",
    "model_path = os.path.join('./model')\n",
    "name = \"ResInceptionv3\"\n",
    "model = model.to(DEVICE)\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    val_acc = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for images,labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy(preds, labels)\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_train_acc = train_acc / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images,labels in tqdm(val_loader):\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            preds = model(images)\n",
    "            loss = criterion(preds, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += accuracy(preds, labels)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_acc = val_acc / len(val_loader)\n",
    "\n",
    "    schedular.step(avg_val_loss)\n",
    "\n",
    "    print(\"Epoch : {} \\ntrain_loss : {:.6f}, \\tTrain_acc : {:.6f}, \\nVal_loss : {:.6f}, \\tVal_acc : {:.6f}\".format(epoch + 1,\n",
    "                                                                                                                   avg_train_loss, avg_train_acc,\n",
    "                                                                                                                   avg_val_loss, avg_val_acc))\n",
    "    if avg_val_loss <= val_loss_min:\n",
    "        print('Validation loss decreased from ({:.6f} --> {:.6f}).\\nSaving model ...'.format(val_loss_min, avg_val_loss))\n",
    "        torch.save(model,os.path.join(model_path,f\"{name}.pth\"))\n",
    "        val_loss_min = avg_val_loss\n",
    "        max_e = 20\n",
    "    max_e -= 1\n",
    "    if max_e<=0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = \"ResInceptionv3\"\n",
    "model = torch.load(os.path.join(model_path,f\"{name}.pth\"))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_loss=0\n",
    "    test_acc=0\n",
    "    for images,labels in tqdm(test_loader):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, labels)\n",
    "        test_loss += loss.item()\n",
    "        test_acc += accuracy(preds, labels)\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    avg_test_acc = test_acc / len(test_loader)\n",
    "    print(\"Test_loss : {:.6f}, \\tTest_acc : {:.6f}\".format(avg_test_loss,avg_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"ResInceptionv3\"\n",
    "model = torch.load(os.path.join(model_path,f\"{name}.pth\"))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "M = np.zeros((4,4))\n",
    "with torch.no_grad():\n",
    "    test_loss=0\n",
    "    test_acc=0\n",
    "    for images,labels in tqdm(test_loader):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, labels)\n",
    "        test_loss += loss.item()\n",
    "        test_acc += accuracy(preds, labels)\n",
    "        \n",
    "        M[preds.argmax(),labels[0]]+=1\n",
    "        \n",
    "    \n",
    "    print(M)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9840a8de2b5de678e209fd904f7d6f8e9cbfcc43f84beeb436e5d7726cf947f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
